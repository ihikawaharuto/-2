
# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: streamlit numpy pandas transformers accelerate sentencepiece fugashi unidic-lite ipadic torch torchvision torchaudio annoy
import streamlit as st
import torch
import numpy as np
import time
import base64
import pickle
import os
import logging
from transformers import BertJapaneseTokenizer, BertModel
from annoy import AnnoyIndex

# --- ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- å®šæ•° ---
class Config:
    VECTOR_CACHE_PATH = "vectors_cache.npy"
    TEXT_SOURCES_CACHE_PATH = "text_sources_cache.pkl"
    ANNOY_INDEX_PATH = "annoy_index.ann"
    SAFE_FILE = "safe.txt"
    OUT_FILE = "out.txt"
    F_DIM = 768
    VIDEO_PATH = "fire2.mp4"
    CSS_PATH = "style.css"
# --- å‹•ç”»å†ç”Ÿç”¨é–¢æ•° ---
@st.cache_data
def get_video_base64(video_path):
    """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦è¿”ã™"""
    if not os.path.exists(video_path):
        st.warning(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
        return None
    with open(video_path, "rb") as file:
        return base64.b64encode(file.read()).decode()

def get_video_html(video_path="fire2.mp4", width=150):
    """å‹•ç”»ã‚’å†ç”Ÿã™ã‚‹ãŸã‚ã®HTMLæ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹"""
    video_base64 = get_video_base64(video_path)
    if video_base64:
        return f"""
            <video autoplay muted loop width="{width}" style="border-radius: 10px; margin-top: 20px; mix-blend-mode: add;">            
                <source src="data:video/mp4;base64,{video_base64}" type="video/mp4">
            </video>"""
    return ""


# --- ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®èª­ã¿è¾¼ã¿ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ã) ---
@st.cache_resource
def load_model_and_tokenizer():
    """BERTãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚"""
    try:
        logging.info("Loading BERT model and tokenizer...")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-v2')
        model = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-v2')
        model.to(device)
        model.eval()
        logging.info("Model and tokenizer loaded successfully.")
        return tokenizer, model, device
    except ImportError as e:
        logging.error(f"Import error during model loading: {e}")
        st.error(f"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
        st.error("pip install -r requirements.txt ãªã©ã§ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª (transformers, torch, fugashi, unidic-liteãªã©) ãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    except Exception as e:
        logging.error(f"An unexpected error occurred during model loading: {e}")
        st.error(f"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

tokenizer, model, device = load_model_and_tokenizer()

# --- ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆè¨ˆç®—ã‚¯ãƒ©ã‚¹ ---
class EngagementCalculator:
    def calculate(self, followers, buzz_score, post_type):
        """
        ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆï¼ˆã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã€ãƒªãƒã‚¹ãƒˆã€ã„ã„ã­ï¼‰ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
        :param followers: ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°
        :param buzz_score: ãƒã‚ºã‚¹ã‚³ã‚¢ (0-100)
        :param post_type: 'SAFE' ã¾ãŸã¯ 'OUT'
        :return: (ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°, ãƒªãƒã‚¹ãƒˆæ•°, ã„ã„ã­æ•°)
        """
        p = 1 if post_type == 'OUT' else 0
        i = int(followers * 0.3 + followers**0.1 * (1 + 210970 * (buzz_score / 100)**3.2 * (1 + 0.5 * (buzz_score / 100)**5 * p)))
        r = int(i * 0.01 * (1 + 2 * (buzz_score / 100)**2) * (1 + p))
        l = int(i * 0.03 * (1 + 0.5 * (buzz_score / 100)**0.7) * (1 + 0.1 * p))
        return i, r, l

# --- ãƒ¡ã‚¤ãƒ³ã®åˆ†é¡å™¨ã‚¯ãƒ©ã‚¹ ---
class TextClassifier:
    def __init__(self, config):
        self.config = config
        self.vec = []
        self.text_sources = []
        self.index = AnnoyIndex(self.config.F_DIM, 'angular')
        self._ensure_data_files_exist()

    def _ensure_data_files_exist(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã«ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚"""
        for fname in [self.config.SAFE_FILE, self.config.OUT_FILE]:
            if not os.path.exists(fname):
                logging.warning(f"Data file '{fname}' not found. Creating an empty file.")
                open(fname, 'w', encoding='utf-8').close()

    def get_vector(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã—ã¾ã™ã€‚"""
        with torch.no_grad():
            inputs = tokenizer.encode_plus(text, truncation=True, return_tensors='pt').to(device)
            outputs = model(**inputs)
            return outputs.pooler_output.detach().cpu().numpy()[0]

    def build_index(self):
        """Annoyã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚"""
        logging.info("Building Annoy index...")
        self.index = AnnoyIndex(self.config.F_DIM, 'angular')
        for i, v in enumerate(self.vec):
            self.index.add_item(i, v)
        self.index.build(10) # 10 is the number of trees
        logging.info(f"Annoy index built with {len(self.vec)} items.")


    def save_caches(self):
        """ãƒ™ã‚¯ãƒˆãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚½ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€Annoyã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã—ã¾ã™ã€‚"""
        logging.info("Saving caches and index...")
        np.save(self.config.VECTOR_CACHE_PATH, np.array(self.vec))
        with open(self.config.TEXT_SOURCES_CACHE_PATH, 'wb') as f:
            pickle.dump(self.text_sources, f)
        self.index.save(self.config.ANNOY_INDEX_PATH)
        logging.info("Caches and index saved.")

    def load_from_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"""
        cache_files = [self.config.VECTOR_CACHE_PATH, self.config.TEXT_SOURCES_CACHE_PATH, self.config.ANNOY_INDEX_PATH]
        if all(os.path.exists(p) for p in cache_files):
            try:
                logging.info("Loading data from cache...")
                self.vec = np.load(self.config.VECTOR_CACHE_PATH).tolist()
                with open(self.config.TEXT_SOURCES_CACHE_PATH, 'rb') as f:
                    self.text_sources = pickle.load(f)
                self.index.load(self.config.ANNOY_INDEX_PATH)
                logging.info("Data loaded from cache successfully.")
                return True
            except (IOError, pickle.UnpicklingError, ValueError) as e:
                logging.error(f"Failed to load from cache: {e}. Rebuilding from source.")
                return False
        return False

    def load_from_source(self):
        """ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚"""
        logging.info("Loading data from source text files...")
        self.vec, self.text_sources = [], []
        try:
            with open(self.config.SAFE_FILE, "r", encoding="utf-8") as f:
                texts_safe = [line.strip() for line in f if line.strip()]
            with open(self.config.OUT_FILE, "r", encoding="utf-8") as f:
                texts_out = [line.strip() for line in f if line.strip()]
        except FileNotFoundError as e:
            logging.error(f"Source file not found: {e}")
            st.error(f"ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e.filename}ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        # Process texts and create vectors
        all_texts = [(text, "safe") for text in texts_safe] + [(text, "out") for text in texts_out]
        if not all_texts:
            logging.warning("Source files are empty. Index will be empty.")
            return

        with st.spinner("ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ä¸­..."):
            for text, label in all_texts:
                self.vec.append(self.get_vector(text))
                self.text_sources.append((text, label))        
        
        self.build_index()
        self.save_caches()

    def add_text(self, text, label):
        """
        æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°ã—ã¾ã™ã€‚
        æ³¨æ„: ã“ã®å®Ÿè£…ã§ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã™ã‚‹ãŸã³ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å…¨ä½“ã‚’å†æ§‹ç¯‰ã™ã‚‹ãŸã‚ã€
              ãƒ‡ãƒ¼ã‚¿é‡ãŒå¤šã„å ´åˆã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
        """
        file_path = self.config.SAFE_FILE if label == "safe" else self.config.OUT_FILE
        try:
            with open(file_path, "a", encoding="utf-8") as file:
                file.write(f"{text}\n")
        except IOError as e:
            logging.error(f"Failed to write to {file_path}: {e}")
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {file_path}")
            return None        
        self.vec.append(self.get_vector(text))
        self.text_sources.append((text, label))
        
        self.build_index()
        self.save_caches()
        
        color = "#1e90ff" if label == "safe" else "#ff4500"
        return f"<span style='color: {color};'>{label.upper()} ã«è¿½åŠ ã•ã‚Œã¾ã—ãŸ</span>"

    def judge(self, text):
        """å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ¤å®šã—ã¾ã™ã€‚"""
        if not self.vec or not self.index.get_n_items():
            return "<span style='color: black;'>åˆ¤å®šä¸å¯ (å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“)</span>"
        try:
            vec_x = self.get_vector(text)
            indices, distances = self.index.get_nns_by_vector(vec_x, 1, include_distances=True)
            
            if not indices:
                return "<span style='color: black;'>åˆ¤å®šä¸å¯ (é¡ä¼¼ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)</span>"
            # Annoyã®angularè·é›¢ã¯ sqrt(2(1-cos(angle))) ãªã®ã§ã€cos(angle) = 1 - (dist^2 / 2)
            sim_score = 1 - (distances[0]**2 / 2)
            
            if sim_score < 0.75:
                return f"<span style='color: black;'>åˆ¤å®šä¿ç•™ (é¡ä¼¼åº¦ãŒä½ã„ãŸã‚: {sim_score:.2f})</span>"

            label = self.text_sources[indices[0]][1]
            color = "#1e90ff" if label == "safe" else "#ff4500"
            label_upper = label.upper()
            
            return f"<span style='color: {color}; font-weight: bold;'>{label_upper} (é¡ä¼¼åº¦: {sim_score:.2f})</span>"
        except Exception as e:
            logging.error(f"Judgement error: {e}", exc_info=True)
            return f"<span style='color: black;'>åˆ¤å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ</span>"
# --- CSSãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•° ---
def load_css(file_name):
    """å¤–éƒ¨CSSãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§é©ç”¨ã™ã‚‹"""
    try:
        with open(file_name, "r", encoding="utf-8") as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    except FileNotFoundError:
        st.warning(f"{file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ã‚¶ã‚¤ãƒ³ãŒé©ç”¨ã•ã‚Œã¾ã›ã‚“ã€‚")

# --- UIãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def handle_add_text(classifier, text, label):
    """ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‡¦ç†ã™ã‚‹"""
    if text.strip():
        with st.spinner(f"{label.upper()} ã«è¿½åŠ ä¸­..."):
            msg = classifier.add_text(text, label)
        if msg:
            icon = "âœ…" if label == "safe" else "ğŸ”¥"
            st.markdown(f"{icon} {msg}", unsafe_allow_html=True)
            st.session_state.judgement_result = None # çµæœè¡¨ç¤ºã‚’ãƒªã‚»ãƒƒãƒˆ
    else:
        st.warning("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
# --- Streamlit UI ---
def main():
    st.set_page_config(page_title="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‚ä¸Šåˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ", layout="centered")

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
    if 'judgement_result' not in st.session_state:
        st.session_state.judgement_result = None
    if 'judgement_text' not in st.session_state:
        st.session_state.judgement_text = ""

    # --- å¤–éƒ¨CSSãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ ---
    load_css(Config.CSS_PATH)

    st.markdown("<h1>ç‚ä¸Šåˆ¤å®šã‚·ã‚¹ãƒ†ãƒ </h1>", unsafe_allow_html=True)

    # --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ– ---
    @st.cache_resource
    def get_classifier():
        classifier = TextClassifier(Config())
        if not classifier.load_from_cache():
            classifier.load_from_source()
        return classifier

    try:
        classifier = get_classifier()
    except Exception as e:
        logging.critical(f"Classifier initialization failed: {e}", exc_info=True)
        st.error("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    calculator = EngagementCalculator()

    # --- ã‚¿ãƒ–ã®ä½œæˆ ---
    tab1, tab2 = st.tabs(["ç‚ä¸Šåˆ¤å®š", "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆè¨ˆç®—"])

    # --- ç‚ä¸Šåˆ¤å®šã‚¿ãƒ– ---
    with tab1:
        input_text = st.text_area("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=150, key="text_judge")

        if st.button("åˆ¤å®š", key="judge_button"):
            if input_text.strip():
                with st.spinner("åˆ¤å®šä¸­..."):
                    result = classifier.judge(input_text)
                st.session_state.judgement_text = result
                if "OUT" in result:
                    st.session_state.judgement_result = "OUT"
                elif "SAFE" in result:
                    st.session_state.judgement_result = "SAFE"
                else:
                    st.session_state.judgement_result = "OTHER"
            else:
                st.warning("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                st.session_state.judgement_result = None

        # --- åˆ¤å®šçµæœã®è¡¨ç¤º ---
        if st.session_state.get('judgement_result'):
            st.markdown("---")
            st.markdown("### åˆ¤å®šçµæœ")
            if st.session_state.judgement_result == "OUT":
                col1, col2 = st.columns([3, 2])
                with col1:
                    st.markdown(st.session_state.judgement_text, unsafe_allow_html=True)
                with col2:
                    st.markdown(get_video_html(), unsafe_allow_html=True)
            else:
                st.markdown(st.session_state.judgement_text, unsafe_allow_html=True)

        st.markdown("---")
        st.subheader("åˆ¤å®šçµæœã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("SAFE ã«è¿½åŠ ", key="safe_add"):
                handle_add_text(classifier, input_text, "safe")
        with col2:
            if st.button("OUT ã«è¿½åŠ ", key="out_add"):
                handle_add_text(classifier, input_text, "out")

    # --- ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆè¨ˆç®—ã‚¿ãƒ– ---
    with tab2:
        if 'judgement_result' in st.session_state:
            st.session_state.judgement_result = None # ã‚¿ãƒ–ã‚’åˆ‡ã‚Šæ›¿ãˆãŸã‚‰çµæœè¡¨ç¤ºã‚’ãƒªã‚»ãƒƒãƒˆ
        st.header("ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬")
        followers = st.number_input("ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°", min_value=0, value=10000)
        buzz_score = st.slider("ãƒã‚ºã‚¹ã‚³ã‚¢", min_value=0, max_value=100, value=50)
        post_type = st.radio("æŠ•ç¨¿ã‚¿ã‚¤ãƒ—", ('SAFE', 'OUT'), horizontal=True)

        if st.button("è¨ˆç®—", key="calc_button"):
            impressions, reposts, likes = calculator.calculate(followers, buzz_score, post_type)
            st.markdown("## è¨ˆç®—çµæœ")
            st.markdown(f"""
            <div class="result-box">
                <p><strong>ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°:</strong> {impressions:,}</p>
                <p><strong>ãƒªãƒã‚¹ãƒˆæ•°:</strong> {reposts:,}</p>
                <p><strong>ã„ã„ã­æ•°:</strong> {likes:,}</p>
            </div>
            """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
''